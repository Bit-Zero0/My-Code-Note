---
Type: Note
tags:
  - 数学
  - 概率论
Status: writing
Start-date: 2025-01-01 17:44
Finish-date: 
Modified-date: 2025-01-03 22:12
Publish: false
---

# 估计量的评选标准

在统计学中,我们经常需要通过样本数据来估计总体的未知参数。但是对同一个参数,可能存在多种不同的估计方法。那么,如何判断哪种估计方法更好呢？这就需要一些科学的评选标准。

## 1. 无偏性

==**无偏性是评价估计量的最基本标准**==。简单来说,如果一个估计量的数学期望等于被估计的参数,我们就说这个估计量是无偏的。

> [!note]+ 数学定义
> 设$X_1, X_2, \ldots, X_n$是来自总体$X$的一个样本，$\hat{\theta} = \hat{\theta}(X_1, X_2, \ldots, X_n)$为未知参数$\theta$的估计量。如果$E(\hat{\theta}) = \theta$，则称$\hat{\theta}$为$\theta$的无偏估计量。
>
>**渐近无偏性**：
如果$\lim_{n \to \infty} E(\hat{\theta}) = \theta$，则称$\hat{\theta}$为$\theta$的渐近无偏估计量。


> [!example] 案例1：估计班级平均身高
> 假设我们要估计一个班级的平均身高。我们可以:
> 1. 方法A：随机抽取10名同学测量身高,取其平均值
> 2. 方法B：随机抽取10名同学测量身高,然后统一加2cm后取平均
> 
> 显然,方法A是无偏的,因为它的期望就等于真实的平均身高
> 而方法B是有偏的,因为它的估计值会系统性地比真实值大2cm

> [!example]+ 案例2
> **题目**：设总体$X$的$E(X) = \mu$，$\mu$未知，$x_1, x_2, \ldots, x_n$是来自总体的一个样本，判断以下两个估计量是否为$\mu$的无偏估计量：
> 1.$\hat{\mu}_1 = \frac{x_1}{3} + \frac{2}{3}x_2$
> 2.$\hat{\mu}_2 = \frac{1}{3}x_1 + \frac{1}{4}x_2$
> 
> **解答**：
> 
> 1. 对于$\hat{\mu}_1$：
>   $E(\hat{\mu}_1) = E\left(\frac{x_1}{3} + \frac{2}{3}x_2\right) = \frac{1}{3}E(x_1) + \frac{2}{3}E(x_2) = \frac{1}{3}\mu + \frac{2}{3}\mu = \mu$
>    因此，$\hat{\mu}_1$是$\mu$的无偏估计量。
> 
> 2. 对于$\hat{\mu}_2$：
>   $E(\hat{\mu}_2) = E\left(\frac{1}{3}x_1 + \frac{1}{4}x_2\right) = \frac{1}{3}E(x_1) + \frac{1}{4}E(x_2) = \frac{1}{3}\mu + \frac{1}{4}\mu = \frac{7}{12}\mu$
>    因为$E(\hat{\mu}_2) \neq \mu$，所以$\hat{\mu}_2$不是$\mu$的无偏估计量。

> [!example]+ 案列3
> **题目**：设$x_1, x_2, \ldots, x_n$是来自总体$X$的一个样本，$E(X) = \mu$，$D(X) = \sigma^2$，$\sigma^2$未知，若$C \sum_{i=1}^{n-1} (x_{i+1} - x_i)^2$为$\sigma^2$的无偏估计量，求$C$。
> 
> **解答**：
> 
> 1. 根据无偏性的定义，我们需要$E[C \sum_{i=1}^{n-1} (x_{i+1} - x_i)^2] = \sigma^2$。
> 
> 2. 展开$(x_{i+1} - x_i)^2$：
>   $(x_{i+1} - x_i)^2 = x_{i+1}^2 - 2x_{i+1}x_i + x_i^2$
> 
> 3. 计算期望：
>   $E[(x_{i+1} - x_i)^2] = E(x_{i+1}^2) - 2E(x_{i+1}x_i) + E(x_i^2)$
>    由于$x_i$和$x_{i+1}$独立同分布，$E(x_{i+1}x_i) = E(x_{i+1})E(x_i) = \mu^2$：
>   $E[(x_{i+1} - x_i)^2] = \sigma^2 + \mu^2 - 2\mu^2 + \sigma^2 + \mu^2 = 2\sigma^2$
> 
> 4. 求$C$：
>   $C \sum_{i=1}^{n-1} E[(x_{i+1} - x_i)^2] = C(n-1)2\sigma^2 = \sigma^2$
>   $C = \frac{1}{2(n-1)}$
> 
> 这样，我们得到了$C$的值，使得$C \sum_{i=1}^{n-1} (x_{i+1} - x_i)^2$成为$\sigma^2$的无偏估计量。

> [!example]- 案列4
> **题目**：假设我们有一个样本$X_1, X_2, \ldots, X_n$来自二项分布$B(1, p)$，其中$p$是成功的概率，且未知。我们需要估计$p$并检查估计量的无偏性。
> 
> **解答**：
> 1. **估计量的构造**：
>    一个自然的选择作为$p$的估计量是样本均值：
>   $\hat{p} = \frac{1}{n} \sum_{i=1}^{n} X_i$
> 
> 2. **检查无偏性**：
>    我们需要计算$\hat{p}$的期望值：
>   $E(\hat{p}) = E\left(\frac{1}{n} \sum_{i=1}^{n} X_i\right) = \frac{1}{n} \sum_{i=1}^{n} E(X_i)$
>    由于$X_i$服从二项分布$B(1, p)$，我们知道$E(X_i) = p$：
>   $E(\hat{p}) = \frac{1}{n} \sum_{i=1}^{n} p = \frac{1}{n} \cdot n \cdot p = p$
> 
>    因为$E(\hat{p}) = p$，所以$\hat{p}$是$p$的无偏估计量。


> [!example]- 案例5
> **题目**：假设我们有一个样本$X_1, X_2, \ldots, X_n$来自正态分布$N(\mu, \sigma^2)$，其中$\mu$是已知的，$\sigma^2$是未知的。我们需要估计$\sigma^2$并检查估计量的无偏性。
> 
> **解答**：
> 1. **估计量的构造**：
>    一个常见的$\sigma^2$的估计量是：
>   $\hat{\sigma}^2 = \frac{1}{n} \sum_{i=1}^{n} (X_i - \mu)^2$
> 
> 2. **检查无偏性**：
>    我们需要计算$\hat{\sigma}^2$的期望值：
>   $E(\hat{\sigma}^2) = E\left(\frac{1}{n} \sum_{i=1}^{n} (X_i - \mu)^2\right)$
>    由于$X_i$服从正态分布$N(\mu, \sigma^2)$，我们知道$E[(X_i - \mu)^2] = \sigma^2$：
>   $E(\hat{\sigma}^2) = \frac{1}{n} \sum_{i=1}^{n} E[(X_i - \mu)^2] = \frac{1}{n} \cdot n \cdot \sigma^2 = \sigma^2$
> 
>    但是，这个估计量是有偏的。为了得到无偏估计量，我们通常使用：
>   $\tilde{\sigma}^2 = \frac{1}{n-1} \sum_{i=1}^{n} (X_i - \mu)^2$
> 
>    这个调整后的估计量的期望值是：
>   $E(\tilde{\sigma}^2) = \frac{n}{n-1} \cdot \sigma^2$
>    为了使其无偏，我们需要进一步调整：
>   $\hat{\sigma}^2_{unbiased} = \frac{n}{n-1} \cdot \frac{1}{n} \sum_{i=1}^{n} (X_i - \mu)^2$
>   $E(\hat{\sigma}^2_{unbiased}) = \sigma^2$
> 
> 这样，$\hat{\sigma}^2_{unbiased}$就是$\sigma^2$的无偏估计量。





## 2. 有效性

在满足无偏性的前提下,==我们希望估计量的波动越小越好==。这就引入了有效性的概念。

> [!note] 数学定义
> 设$\hat{\theta}_1$和$\hat{\theta}_2$都是$\theta$的无偏估计量,如果:
>$Var(\hat{\theta}_1) \leq Var(\hat{\theta}_2)$
> 则称$\hat{\theta}_1$比$\hat{\theta}_2$更有效。

**方差越小的估计量,说明其估计值越集中在真实参数周围,估计的准确度越高。**

> [!example] 案例：两种测量方法
> 假设有两种温度计测量水温:
> - 温度计A: 误差范围±0.1°C
> - 温度计B: 误差范围±0.5°C
> 
> 虽然两个温度计都能给出正确的平均值(无偏),但温度计A的测量结果更稳定,方差更小,因此更有效。



> [!example]+ 案列2:  
> $X_1, X_2$是来自总体$X \sim N(\mu, 1)$的样本，考虑三个估计量$\hat{\mu}_1 = \frac{1}{2}X_1 + \frac{1}{2}X_2$，$\hat{\mu}_2 = \frac{1}{4}X_1 + \frac{3}{4}X_2$，$\hat{\mu}_3 = \frac{1}{2}X_1 + \frac{1}{2}X_2$。通过计算它们的方差，可以确定哪一个估计量最有效。
>  
> **解答**：
> 1. 计算$\hat{\mu}_1$的方差：
>   $D(\hat{\mu}_1) = D\left(\frac{1}{2}X_1 + \frac{1}{2}X_2\right) = \frac{1}{4}D(X_1) + \frac{1}{4}D(X_2) = \frac{1}{2}$
> 
> 2. 计算$\hat{\mu}_2$的方差：
>   $D(\hat{\mu}_2) = D\left(\frac{1}{4}X_1 + \frac{3}{4}X_2\right) = \frac{1}{16}D(X_1) + \frac{9}{16}D(X_2) = \frac{5}{8}$
> 
> 3. 计算$\hat{\mu}_3$的方差：
>   $D(\hat{\mu}_3) = D\left(\frac{1}{3}X_1 + \frac{2}{3}X_2\right) = \frac{1}{9}D(X_1) + \frac{4}{9}D(X_2) = \frac{5}{9}$
> 
> 比较三个方差，我们可以看到$D(\hat{\mu}_1) = \frac{1}{2}$是最小的，因此$\hat{\mu}_1$是最有效的估计量。


## 3. 一致性(相合性)

==**一致性是指当样本量趋于无穷时,估计量收敛于真实参数的性质**==。这是一个非常重要的性质。

> [!note] 数学定义
> 设$\hat{\theta}_n$是基于样本量n的估计量,如果对于任意小的正数$\epsilon$,有:
>$\lim_{n \to \infty} P(|\hat{\theta}_n - \theta| < \epsilon) = 1$
> 则称$\hat{\theta}_n$是$\theta$的一致估计量。

通俗地说,**样本量越大,估计值就越接近真实值**。

> [!tip] 小贴士
> - 一致性并不要求估计量是无偏的
> - 在实际应用中,一致性是一个非常重要的性质
> - 大多数常用的估计方法(如最大似然估计)都具有一致性

> [!example] 案例：掷骰子
> 假设我们通过掷骰子来估计骰子点数的期望值:
> - 掷10次取平均：可能与真实值(3.5)有一定偏差
> - 掷100次取平均：更接近3.5
> - 掷1000次取平均：几乎就是3.5
> 
> 这就体现了一致性：样本量越大,估计值越准确。

> [!example]+ 案列2
> **题目**：如果$X_1, X_2, \ldots, X_n$来自总体$X \sim N(\mu, \sigma^2)$，考虑样本方差$S^2 = \frac{1}{n} \sum_{i=1}^n (X_i - \overline{X})^2$是否为$\sigma^2$的一致估计。
> 
> **解答**：
> 1. 计算$S^2$的期望：
>   $E(S^2) = E\left(\frac{1}{n} \sum_{i=1}^n (X_i - \overline{X})^2\right) = \sigma^2$
>    这表明$S^2$是$\sigma^2$的无偏估计。
> 
> 2. 计算$S^2$的方差：
>   $D(S^2) = \frac{2\sigma^4}{n-1}$
>    当$n \to \infty$时，$D(S^2) \to 0$。
> 
> 由于$E(S^2) = \sigma^2$且$D(S^2) \to 0$当$n \to \infty$，我们可以得出$S^2$是$\sigma^2$的一致估计。


## 总结

在评价一个估计量的好坏时,我们主要考虑这三个标准：
1. ==无偏性==：估计量的期望等于真实参数
2. ==有效性==：在无偏的前提下,方差越小越好
3. ==**一致性**==：样本量增大时,估计量收敛于真实参数

这些标准不是互斥的,一个好的估计量通常应该同时满足这些性质。


## 练习题
1. 设$X_1, X_2, ..., X_n$是来自总体$X$的一个样本,其中$E(X)=\mu$,$D(X)=\sigma^2$。判断以下估计量是否为$\mu$的无偏估计:$\hat{\mu} = \frac{1}{2}X_1 + \frac{1}{3}X_2 + \frac{1}{6}\sum_{i=3}^n X_i$

> [!tip]- 解题思路与解答
> **解题思路**:
> 1. 根据无偏性的定义,需要验证$E(\hat{\mu})=\mu$
> 2. 利用期望的线性性质
> 3. 注意所有样本的期望都是$\mu$
> 
> **详细解答**:
> $E(\hat{\mu}) = E(\frac{1}{2}X_1 + \frac{1}{3}X_2 + \frac{1}{6}\sum_{i=3}^n X_i)$
> $= \frac{1}{2}E(X_1) + \frac{1}{3}E(X_2) + \frac{1}{6}\sum_{i=3}^n E(X_i)$
> $= \frac{1}{2}\mu + \frac{1}{3}\mu + \frac{1}{6}(n-2)\mu$
> $= (\frac{1}{2} + \frac{1}{3} + \frac{n-2}{6})\mu$
> $= (1)\mu = \mu$
> 
> 因此,$\hat{\mu}$是$\mu$的无偏估计。


2. 设$X_1, X_2$是来自正态总体$N(\mu,\sigma^2)$的样本,其中$\mu$未知,$\sigma^2$已知。比较下列两个估计量的有效性:$\hat{\mu}_1 = \frac{X_1 + X_2}{2}$和$\hat{\mu}_2 = \frac{3X_1 + X_2}{4}$
> [!tip]- 解题思路与解答
> 
> **解题思路**:
> 1. 首先验证两个估计量是否都是无偏的
> 2. 计算两个估计量的方差
> 3. 比较方差大小
> 
> **详细解答**:
> 1. 验证无偏性:
>    $E(\hat{\mu}_1) = E(\frac{X_1 + X_2}{2}) = \frac{1}{2}(\mu + \mu) = \mu$
>    $E(\hat{\mu}_2) = E(\frac{3X_1 + X_2}{4}) = \frac{3}{4}\mu + \frac{1}{4}\mu = \mu$
>    两者都是无偏的
> 
> 2. 计算方差:
>    $D(\hat{\mu}_1) = D(\frac{X_1 + X_2}{2}) = \frac{1}{4}(2\sigma^2) = \frac{\sigma^2}{2}$
>    $D(\hat{\mu}_2) = D(\frac{3X_1 + X_2}{4}) = \frac{9}{16}\sigma^2 + \frac{1}{16}\sigma^2 = \frac{5\sigma^2}{8}$
> 
> 3. 比较: $\frac{\sigma^2}{2} < \frac{5\sigma^2}{8}$
> 
> 因此,$\hat{\mu}_1$比$\hat{\mu}_2$更有效。


3. 设$X_1, X_2, ..., X_n$是来自总体$X$的样本,总体均值$\mu$未知。证明样本均值$\overline{X}$是$\mu$的一致估计量。
> [!tip]- 解题思路与解答
> 
> **解题思路**:
> 1. 利用切比雪夫不等式
> 2. 证明当$n \to \infty$时,对任意$\epsilon > 0$,有$P(|\overline{X} - \mu| < \epsilon) \to 1$
> 
> **详细解答**:
> 1. 由切比雪夫不等式:
>    $P(|\overline{X} - \mu| \geq \epsilon) \leq \frac{D(\overline{X})}{\epsilon^2}$
> 
> 2. 计算$D(\overline{X})$:
>    $D(\overline{X}) = D(\frac{1}{n}\sum_{i=1}^n X_i) = \frac{\sigma^2}{n}$
> 
> 3. 代入不等式:
>    $P(|\overline{X} - \mu| \geq \epsilon) \leq \frac{\sigma^2}{n\epsilon^2}$
> 
> 4. 当$n \to \infty$时:
>    $\lim_{n \to \infty} P(|\overline{X} - \mu| \geq \epsilon) = 0$
>    即$\lim_{n \to \infty} P(|\overline{X} - \mu| < \epsilon) = 1$
> 
> 因此,$\overline{X}$是$\mu$的一致估计量。


4. 设$X_1, X_2, ..., X_n$是来自参数为$\lambda$的泊松分布的样本。证明$\hat{\lambda} = \overline{X}$同时具有无偏性和一致性。
> [!tip]- 解题思路与解答
> 
> **解题思路**:
> 1. 先证明无偏性
> 2. 再证明一致性
> 3. 注意泊松分布的性质:$E(X)=\lambda$, $D(X)=\lambda$
> 
> **详细解答**:
> 1. 证明无偏性:
>    $E(\hat{\lambda}) = E(\overline{X}) = \frac{1}{n}\sum_{i=1}^n E(X_i) = \lambda$
> 
> 2. 证明一致性:
>    利用切比雪夫不等式:
>    $D(\hat{\lambda}) = D(\overline{X}) = \frac{\lambda}{n}$
>    $P(|\hat{\lambda} - \lambda| \geq \epsilon) \leq \frac{\lambda}{n\epsilon^2} \to 0$ (当$n \to \infty$)
> 
> 因此,$\hat{\lambda}$同时具有无偏性和一致性。


5. 设$X_1, X_2, ..., X_n$是来自均匀分布$U(0,\theta)$的样本,其中$\theta$未知。考虑估计量$\hat{\theta} = 2\overline{X}$。请判断该估计量的无偏性。
> [!tip]- 解题思路与解答
> 
> **解题思路**:
> 1. 回忆均匀分布的性质:$E(X)=\frac{\theta}{2}$
> 2. 计算$E(\hat{\theta})$并与$\theta$比较
> 
> **详细解答**:
> 1. $E(\hat{\theta}) = E(2\overline{X})$
>    $= 2E(\frac{1}{n}\sum_{i=1}^n X_i)$
>    $= 2 \cdot \frac{1}{n}\sum_{i=1}^n E(X_i)$
>    $= 2 \cdot \frac{\theta}{2}$
>    $= \theta$
> 
> 2. 由于$E(\hat{\theta}) = \theta$
> 
> 因此,$\hat{\theta}$是$\theta$的无偏估计量。
